{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note: This code is experimental. \n",
    "\n",
    "### These are some attempts to get a CNN model working with healpix coordinates. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN on healpix model (not working):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "from src.cone_model import ToyModel3DCone, HEALPixCone\n",
    "from src.loss import ApproxLoss\n",
    "from src.model import ApproxModel\n",
    "from src.config import Config\n",
    "from src.train import TrainerMain as Trainer\n",
    "from src.utils import set_seed, ensure_dir_exists\n",
    "\n",
    "import nnhealpix\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Config\n",
    "    config = Config()\n",
    "    config.model_type = 'conv'\n",
    "    config.loss_type = 'MSELoss'\n",
    "    config.metric_monitor = 'loss'\n",
    "    config.lr = 1e-3\n",
    "    config.dropout_rate = 0.0\n",
    "    config.train_batch_size = 1024 # number of inputs to process before updating the model (backpropagation). PREV 1024\n",
    "    config.eval_batch_size = 1024 # PREV 1024\n",
    "    config.epoch = 5000\n",
    "    config.device = 'cpu'\n",
    "    \n",
    "    \n",
    "    # flattened = True for using fully-connected layers, False for using conv-based layers\n",
    "    config.flattened = False  \n",
    "    config.filter_size = 3\n",
    "    config.NSIDE = 8 # number of constant latitude rings. larger means significantly more parameters. PREV 6. \n",
    "    config.exp_name = 'sphere_{}_{}_NSIDE{}_datasize1024'.format(\n",
    "       config.model_type, config.loss_type, config.NSIDE)\n",
    "    config.working_dir = os.path.join('results', \n",
    "        '{}_{}'.format(config.exp_name, time.strftime('%m%d_%H-%M'))\n",
    "    )\n",
    "    ensure_dir_exists(config.working_dir)\n",
    "    config.dump(os.path.join(config.working_dir, 'config.json'))\n",
    "    \n",
    "\n",
    "    set_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    \n",
    "Generation and saving of the dataset.\n",
    "\n",
    "'''\n",
    "\n",
    "cone_model = HEALPixCone(\n",
    "        output_dir=os.path.join(config.working_dir, 'figs'),\n",
    "        NSIDE=config.NSIDE\n",
    ")\n",
    "\n",
    "train_dset = cone_model.create_dataset(dataset_size=1024) \n",
    "val_dset = cone_model.create_dataset(dataset_size=1024)   \n",
    "f = open(f\"sphere_datasets_NSIDE{config.NSIDE}.pkl\", \"wb\")\n",
    "pickle.dump((train_dset, val_dset), f)\n",
    "f.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Open the dataset.\n",
    "'''\n",
    "\n",
    "f = open(f\"sphere_datasets_NSIDE{config.NSIDE}.pkl\", \"rb\")\n",
    "train_dset, val_dset = pickle.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Create the training and validation datasets. Do any necessary reshapping. \n",
    "\n",
    "'''\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "# versions of y_train/y_proj that aren't just flattened. Meaning you have 4 separate images (or however many there are based on depth) that you can project onto the globe.\n",
    "y_train_proj = [] \n",
    "y_val_proj = []\n",
    "\n",
    "\n",
    "for i in range(len(train_dset)):\n",
    "    x_train.append(train_dset[i]['data'].reshape(2,1))  # can index like dictionary to get ith data entry (data, label) pair\n",
    "    x_val.append(val_dset[i]['data'].reshape(2,1))\n",
    "\n",
    "    # flattened version\n",
    "    y_train.append(train_dset[i]['label'])\n",
    "    y_val.append(val_dset[i]['label'])\n",
    "\n",
    "    # non flattened version\n",
    "    # y_train.append(val_dset[i]['label'].reshape(768, 4)) # 4 is depth. second # is length of train_dset / depth which is used for size of each healpix globe thing (# pixels) \n",
    "    # y_val.append(val_dset[i]['label'].reshape(768, 4))\n",
    "\n",
    "    # add versions of y_train/val that can be projected onto the sphere\n",
    "    y_train_proj.append(val_dset[i]['label'].reshape(4, 768)) # 4 is depth. second # is length of train_dset / depth which is used for size of each healpix globe thing (# pixels). will take first 768 then start new row.\n",
    "    y_val_proj.append(val_dset[i]['label'].reshape(4, 768))\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "y_train_proj = np.array(y_train_proj)\n",
    "y_val_proj = np.array(y_val_proj)\n",
    "\n",
    "print(\"x train dim: \", x_train.shape)\n",
    "print(\"y train dim: \", y_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"x val dim: \", x_val.shape)\n",
    "print(\"y val dim: \", y_val.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"y projection version dim: \", y_train_proj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Make image of one of the data points to make sure the file reading/reshaping is correct.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "hp.projview(\n",
    "    y_train_proj[25][2], # first number is which datapoint and second is which cone depth (1-4)\n",
    "    coord=[\"G\"],\n",
    "    graticule=True,\n",
    "    graticule_labels=True,\n",
    "    unit=\"cbar label\",\n",
    "    xlabel=\"longitude\",\n",
    "    ylabel=\"latitude\",\n",
    "    cb_orientation=\"horizontal\",\n",
    "    projection_type=\"mollweide\",\n",
    ")\n",
    "plt.savefig(\"mygraph.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "Create the model.\n",
    "\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, activations\n",
    "import nnhealpix.layers\n",
    "\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(2, 1)) # inputs of the convolution part\n",
    "input_NSIDE = config.NSIDE\n",
    "\n",
    "# I will be using the functional API for keras (functions to make model) since more flexible than sequential.\n",
    "\n",
    "# # blow it up\n",
    "conv = layers.Dense(3072)(inputs)\n",
    "conv = layers.Activation('relu')(conv) \n",
    "\n",
    "# add convolutions\n",
    "conv = nnhealpix.layers.ConvNeighbours(input_NSIDE, filters=32, kernel_size=9)(inputs)  # i think filters should be multple of 3072\n",
    "conv = layers.Activation('relu')(conv) # activation after every convolution\n",
    "\n",
    "# conv = nnhealpix.layers.ConvNeighbours(input_NSIDE, filters=32, kernel_size=9)(conv)\n",
    "# conv = tf.keras.layers.Activation('relu')(conv) # activation after every convolution\n",
    "\n",
    "# conv = nnhealpix.layers.ConvNeighbours(input_NSIDE, filters=4, kernel_size=9)(conv)\n",
    "# conv = tf.keras.layers.Activation('relu')(conv) # activation after every convolution\n",
    "\n",
    "\n",
    "# # add a maxpooling layer\n",
    "# conv = nnhealpix.layers.MaxPooling(input_NSIDE, 4)(conv) # for maxpooling params: (NSIDE_IN, NSIDE_OUT). NSIDE_OUT must be lower power of 2 based on files in library.\n",
    "# conv = tf.keras.layers.Dropout(0.2)(conv) # add dropout to prevent overfitting\n",
    "\n",
    "# flatten to pass to next part!\n",
    "conv = layers.Flatten()(conv)\n",
    "\n",
    "# # regular fully connected part\n",
    "# conv = tf.keras.layers.Dense(1024)(conv)\n",
    "# conv = tf.keras.layers.Activation('relu')(conv)\n",
    "\n",
    "# conv = tf.keras.layers.Dense(2048)(conv)\n",
    "# conv = tf.keras.layers.Activation('relu')(conv)\n",
    "\n",
    "conv = layers.Dense(3072)(conv) # 768 * 4\n",
    "out = layers.Activation('softmax')(conv)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=out)\n",
    "model.compile(loss=tf.keras.losses.mse, optimizer=tf.keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=1000, validation_data=(x_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Fully Connected Network with Healpix (works)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Unlike above, the x train will be just lists of 2 for each data point (not 2, 1)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_val = []\n",
    "y_val = []\n",
    "\n",
    "# versions of y_train/y_proj that aren't just flattened. Meaning you have 4 separate images (or however many there are based on depth) that you can project onto the globe.\n",
    "y_train_proj = [] \n",
    "y_val_proj = []\n",
    "\n",
    "\n",
    "for i in range(len(train_dset)):\n",
    "    x_train.append(train_dset[i]['data'])  # can index like dictionary to get ith data entry (data, label) pair\n",
    "    x_val.append(val_dset[i]['data'])\n",
    "\n",
    "    # flattened version\n",
    "    y_train.append(train_dset[i]['label'])\n",
    "    y_val.append(val_dset[i]['label'])\n",
    "\n",
    "    # non flattened version\n",
    "    # y_train.append(val_dset[i]['label'].reshape(768, 4)) # 4 is depth. second # is length of train_dset / depth which is used for size of each healpix globe thing (# pixels) \n",
    "    # y_val.append(val_dset[i]['label'].reshape(768, 4))\n",
    "\n",
    "    # add versions of y_train/val that can be projected onto the globe\n",
    "    y_train_proj.append(val_dset[i]['label'].reshape(4, 768)) # 4 is depth. second # is length of train_dset / depth which is used for size of each healpix globe thing (# pixels). will take first 768 then start new row.\n",
    "    y_val_proj.append(val_dset[i]['label'].reshape(4, 768))\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "y_train_proj = np.array(y_train_proj)\n",
    "y_val_proj = np.array(y_val_proj)\n",
    "\n",
    "print(\"x train dim: \", x_train.shape)\n",
    "print(\"y train dim: \", y_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"x val dim: \", x_val.shape)\n",
    "print(\"y val dim: \", y_val.shape)\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"y projection version dim: \", y_train_proj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "Create the model.\n",
    "\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, activations\n",
    "import nnhealpix.layers\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "Working FCNN. \n",
    "\n",
    "'''\n",
    "\n",
    "inputs = layers.Input(shape=(2, )) # inputs of the convolution part\n",
    "input_NSIDE = config.NSIDE\n",
    "\n",
    "# I will be using the functional API for keras (functions to make model) since more flexible than sequential.\n",
    "\n",
    "conv = layers.Dense(10)(inputs)\n",
    "conv = layers.Activation('relu')(conv) \n",
    "\n",
    "conv = layers.Dense(1000)(conv)\n",
    "conv = layers.Activation('relu')(conv) \n",
    "\n",
    "# conv = layers.Dense(1000)(conv)\n",
    "# conv = layers.Activation('relu')(conv) \n",
    "\n",
    "conv = layers.Dense(1000)(conv)\n",
    "conv = layers.Activation('relu')(conv) \n",
    "\n",
    "out = layers.Dense(3072)(conv) # 768 * 4\n",
    "# out = layers.Activation('softmax')(conv)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=out)\n",
    "model.compile(loss=tf.keras.losses.mse, optimizer=tf.keras.optimizers.Adam(lr=0.01)) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=200, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_train)\n",
    "\n",
    "one_pred = pred[35].reshape(4, 768)\n",
    "\n",
    "\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "hp.projview(\n",
    "    one_pred[2], # first number is which datapoint and second is which cone depth (1-4)\n",
    "    coord=[\"G\"],\n",
    "    graticule=True,\n",
    "    graticule_labels=True,\n",
    "    unit=\"cbar label\",\n",
    "    xlabel=\"longitude\",\n",
    "    ylabel=\"latitude\",\n",
    "    cb_orientation=\"horizontal\",\n",
    "    projection_type=\"mollweide\",\n",
    ")\n",
    "plt.savefig(\"mygraph.png\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING CNN BASED ON OUTPUT OF FULLY CONNECTED (failed): \n",
    "\n",
    "Loss was not reducing. I tried to restrict it to only one depth of the cone that it was predicting but that didn't work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for training set and val set\n",
    "\n",
    "# train_pred = model.predict(x_train)\n",
    "# val_pred = model.predict(x_val)\n",
    "\n",
    "# reshape to be (1024 by 3072 by 1) instead of just 1024 by 3072. this is how the conv layer wants it.\n",
    "\n",
    "train_pred = train_pred.reshape(1024, 4, 768, 1);\n",
    "val_pred = val_pred.reshape(1024, 4, 768, 1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets only get one depth of it\n",
    "cnn_x_train = []\n",
    "cnn_x_val = []\n",
    "\n",
    "# lets only get one depth of it\n",
    "cnn_y_train = []\n",
    "cnn_y_val = []\n",
    "\n",
    "# y trains from beginning but reshaped  with onyl one depth\n",
    "temp_y_train = y_train.reshape(1024, 4, 768)\n",
    "temp_y_val = y_val.reshape(1024, 4, 768)\n",
    "\n",
    "\n",
    "depth = 2\n",
    "\n",
    "for i in range(len(train_pred)):\n",
    "    cnn_x_train.append(train_pred[i][depth])\n",
    "    cnn_y_train.append(temp_y_train[i][depth])\n",
    "\n",
    "for i in range(len(val_pred)):\n",
    "    cnn_x_val.append(val_pred[i][depth])\n",
    "    cnn_y_val.append(temp_y_val[i][depth])\n",
    "\n",
    "cnn_x_train = np.array(cnn_x_train)\n",
    "cnn_x_val = np.array(cnn_x_val)\n",
    "\n",
    "\n",
    "cnn_y_train = np.array(cnn_y_train)\n",
    "cnn_y_val = np.array(cnn_y_val)\n",
    "\n",
    "print(\"cnn x train shape: \", cnn_x_train.shape)\n",
    "print(\"cnn y train shape: \", cnn_y_train.shape)\n",
    "\n",
    "print(\"cnn x val shape: \", cnn_x_val.shape)\n",
    "print(\"cnn y val shape: \", cnn_y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Create the model.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, activations\n",
    "import nnhealpix.layers\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(768, 1)) # inputs of the convolution part\n",
    "input_NSIDE = config.NSIDE\n",
    "\n",
    "# add convolutions\n",
    "cnn = nnhealpix.layers.ConvNeighbours(input_NSIDE, filters=40, kernel_size=9)(inputs)  # i think filters should be multple of 3072\n",
    "cnn = layers.Activation('relu')(cnn) # activation after every convolution\n",
    "\n",
    "cnn = nnhealpix.layers.ConvNeighbours(input_NSIDE, filters=40, kernel_size=9)(cnn)\n",
    "cnn = tf.keras.layers.Activation('relu')(cnn) # activation after every convolution\n",
    "\n",
    "\n",
    "# # add a maxpooling layer\n",
    "# cnn = nnhealpix.layers.MaxPooling(input_NSIDE, 4)(cnn) # for maxpooling params: (NSIDE_IN, NSIDE_OUT). NSIDE_OUT must be lower power of 2 based on files in library.\n",
    "# cnn = tf.keras.layers.Dropout(0.2)(cnn) # add dropout to prevent overfitting\n",
    "\n",
    "# flatten to pass to next part!\n",
    "cnn = layers.Flatten()(cnn)\n",
    "\n",
    "cnn = layers.Dense(768)(cnn) # 768 * 4\n",
    "out = layers.Activation('softmax')(cnn)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=out)\n",
    "model.compile(loss=tf.keras.losses.mse, optimizer=tf.keras.optimizers.Adam(lr=0.01), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(cnn_x_train, cnn_y_train, epochs=1000, validation_data=(cnn_x_val, cnn_y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

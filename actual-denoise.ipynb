{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup: Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.cone_model import HEALPixCone\n",
    "\n",
    "# data_NSIDE = 32\n",
    "\n",
    "# cone_model = HEALPixCone(\n",
    "#         output_dir=os.path.join(\"\", 'figs'),\n",
    "#         NSIDE=data_NSIDE\n",
    "# )\n",
    "\n",
    "# train_dset = cone_model.create_dataset(dataset_size=1024)\n",
    "# val_dset = cone_model.create_dataset(dataset_size=1024)   \n",
    "# f = open(f\"sphere_datasets_NSIDE{config.NSIDE}.pkl\", \"wb\"); pickle.dump((train_dset, val_dset), f); f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Important Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSIDE = 32\n",
    "NUMPIX = 12 * NSIDE ** 2\n",
    "DEPTH = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "\n",
    "def make_dir():\n",
    "    image_dir = 'Saved_Images'\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 12 * NSIDE // 8, 64 * NSIDE // 8)\n",
    "    save_image(img, name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "base = torch.float32\n",
    "\n",
    "#pin to gpu\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Seed for Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import set_seed\n",
    "set_seed(2021)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Open the file.\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_name = f\"sphere_datasets_NSIDE{NSIDE}.pkl\"\n",
    "\n",
    "f = open(file_name, \"rb\")\n",
    "train_dset, val_dset = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "test = np.array(train_dset)\n",
    "\n",
    "print(len(train_dset), len(val_dset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reshape Data into Rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Create the training and validation datasets. Do any necessary reshaping. \n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "y_combined = []\n",
    "\n",
    "# NOTE: Can change based on input size of data\n",
    "# For now, default to 12, 64 size for NSIDE 8 that is scaled up for larger NSIDEs. \n",
    "length = 64 * NSIDE // 8\n",
    "width = 12 * NSIDE // 8\n",
    "rect_shape = (1, width, length)\n",
    "\n",
    "NUM_CHANNELS = 1\n",
    "\n",
    "for i in range(len(train_dset)):\n",
    "    all_train_depths = train_dset[i]['label'].reshape(NUM_CHANNELS, DEPTH, NUMPIX)\n",
    "    all_val_depths = val_dset[i]['label'].reshape(NUM_CHANNELS, DEPTH, NUMPIX)\n",
    "\n",
    "    # [0] just so you can get inside the list (only one channel)\n",
    "    for j in range(4):\n",
    "        y_combined.append(all_train_depths[0][j].reshape(rect_shape))\n",
    "        y_combined.append(all_val_depths[0][j].reshape(rect_shape))\n",
    "\n",
    "y_combined = np.array(y_combined)\n",
    "\n",
    "print(\"y_combined shape: \", y_combined.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Split Data into Train, Val, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(0.8 * len(y_combined)) # 70%\n",
    "val_len = int(0.15 * len(y_combined)) - train_len # 15%\n",
    "test_len = len(y_combined) - train_len - val_len # 15%\n",
    "\n",
    "y_train = y_combined[:train_len]\n",
    "y_val = y_combined[:val_len]\n",
    "y_test = y_combined[:test_len]\n",
    "\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_val shape: \", y_val.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Noisy Versions of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 0, 0.3 # mu is the mean, sigma is the standard deviation of the noise distribution\n",
    "\n",
    "x_combined = []\n",
    "\n",
    "noise_shape = rect_shape\n",
    "\n",
    "for y_sample in y_combined:\n",
    "    # Create array of noise of how many pixels there are\n",
    "    noise = np.random.normal(mu, sigma, noise_shape)\n",
    "\n",
    "    x_combined.append(y_sample + noise)\n",
    "\n",
    "x_combined = np.array(x_combined)\n",
    "\n",
    "print(\"x_combined shape: \", x_combined.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Test, Val, and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(0.8 * len(y_combined)) # 70%\n",
    "val_len = int(0.15 * len(y_combined)) - train_len # 15%\n",
    "test_len = len(y_combined) - train_len - val_len # 15%\n",
    "\n",
    "y_train = y_combined[:train_len]\n",
    "y_val = y_combined[:val_len]\n",
    "y_test = y_combined[:test_len]\n",
    "\n",
    "x_train = x_combined[:train_len]\n",
    "x_val = x_combined[:val_len]\n",
    "x_test = x_combined[:test_len]\n",
    "\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_val shape: \", y_val.shape)\n",
    "print(\"y_test shape: \", y_test.shape)\n",
    "print()\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_val shape: \", x_val.shape)\n",
    "print(\"x_test shape: \", x_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print sample of the noisy healpix data vs. actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM = 333\n",
    "\n",
    "# [0] since 1 channel\n",
    "sample_x = x_train[NUM][0]\n",
    "sample_y = y_train[NUM][0]\n",
    "\n",
    "plt.imshow(sample_x)\n",
    "\n",
    "hp.mollview(sample_x.reshape(NUMPIX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sample_y, interpolation='nearest')\n",
    "hp.mollview(sample_y.reshape(NUMPIX))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create Dataset and DataLoader\n",
    "\n",
    "Dataset is wrapper for data with labels, DataLoader is wrapper around that in iterable form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 32 # previously 1\n",
    "NOISE_FACTOR = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# class GammaDataset(Dataset):\n",
    "#     def __init__(self, x, y):\n",
    "#         self.x = x\n",
    "#         self.y = y\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.x)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         return self.x[index], self.y[index]\n",
    "\n",
    "# train_set = GammaDataset(x_train.to, y_train)\n",
    "# val_set = GammaDataset(x_val, y_val)\n",
    "# test_set = GammaDataset(x_test, y_test)\n",
    "\n",
    "# the \"to(torch.float32) is to make it compatible with cpu. We want base 32.\"\n",
    "\n",
    "train_set = TensorDataset(torch.tensor(x_train).to(dtype=base, device=device), torch.tensor(y_train).to(dtype=base, device=device))\n",
    "val_set = TensorDataset(torch.tensor(x_val).to(dtype=base, device=device), torch.tensor(y_val).to(dtype=base, device=device))\n",
    "test_set = TensorDataset(torch.tensor(x_test).to(dtype=base, device=device), torch.tensor(y_test).to(dtype=base, device=device))\n",
    "\n",
    "train_loader = DataLoader(train_set, BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_set, BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_set, BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the arrays are of the right type (base 32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val in train_loader:\n",
    "#     tens = val[0]\n",
    "#     print(tens.dtype)\n",
    "\n",
    "el = train_set[0][0][0]\n",
    "el.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Conv2d, Sequential, ConvTranspose2d, ReLU, MaxPool2d\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "IMPORTANT: out_channels is how many filters will be learned for that layer in training\n",
    "--> the feature map for that layer (3D thing of what the layer outputs) is the stack of these channels (filters) \n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "class AutoEncoder(Module): \n",
    "    def __init__(self, IN_CHANNELS, encoder, decoder):\n",
    "        super().__init__()\n",
    "\n",
    "        # Put encoder layers in Sequential container\n",
    "        # First increase from 1 --> 64 channels\n",
    "        # Keep decreasing number of channels\n",
    "        \n",
    "        self.encoder = encoder\n",
    "\n",
    "        self.decoder = decoder\n",
    "\n",
    "    # Run x through each layer\n",
    "    def forward(self, x):\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        \n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_CHANNELS = NUM_CHANNELS # Not RGB, just one value for each pixel. Healpy just adds color by itself. \n",
    "\n",
    "\n",
    "model8_enc = Sequential(\n",
    "            Conv2d(IN_CHANNELS, 64, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Conv2d(32, 16, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            MaxPool2d(2, 2),\n",
    "    )\n",
    "\n",
    "model8_dec = Sequential(\n",
    "            ConvTranspose2d(8, 16, kernel_size=1, stride=1),\n",
    "            ReLU(),\n",
    "            ConvTranspose2d(16, 32, kernel_size=1, stride=1),\n",
    "            ReLU(),\n",
    "            ConvTranspose2d(32, 64, kernel_size=1, stride=1),\n",
    "            ReLU(),\n",
    "            ConvTranspose2d(64, 1, kernel_size=2, stride=2),\n",
    "            ReLU()\n",
    "    )\n",
    "\n",
    "# model for NSIDE=8\n",
    "model8 = AutoEncoder(IN_CHANNELS, model8_enc, model8_dec).to(dtype=base, device=device)\n",
    "print(model8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_CHANNELS = 1 # Not RGB, just one value for each pixel. Healpy just adds color by itself. \n",
    "\n",
    "model32_enc = Sequential(\n",
    "            Conv2d(IN_CHANNELS, 64, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Conv2d(32, 16, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            Conv2d(16, 8, kernel_size=3, padding=1),\n",
    "            ReLU(),\n",
    "            MaxPool2d(2, 2),\n",
    "    )\n",
    "\n",
    "model32_dec = Sequential(\n",
    "            ConvTranspose2d(8, 16, kernel_size=1, stride=1),\n",
    "            ReLU(),\n",
    "            ConvTranspose2d(16, 32, kernel_size=1, stride=1),\n",
    "            ReLU(),\n",
    "            ConvTranspose2d(32, 64, kernel_size=1, stride=1),\n",
    "            ReLU(),\n",
    "            ConvTranspose2d(64, 1, kernel_size=2, stride=2),\n",
    "            ReLU()\n",
    "    )\n",
    "\n",
    "# model for NSIDE=8\n",
    "model32 = AutoEncoder(IN_CHANNELS, model32_enc, model32_dec).to(dtype=base, device=device)\n",
    "print(model32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick which model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Create Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "# Use MSE Loss\n",
    "# need to specify cpu\n",
    "criterion = MSELoss().to(dtype=base, device=device)\n",
    "\n",
    "# Use Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_loss_hist = []\n",
    "val_loss_hist = []\n",
    "epoch = 0\n",
    "\n",
    "def train(model, train_loader, NUM_EPOCHS):\n",
    "    global train_loss_hist\n",
    "    global val_loss_hist\n",
    "    global epoch\n",
    "\n",
    "    while epoch < NUM_EPOCHS:\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Go through each batch of the data (can pass in entire batch at once!)\n",
    "        # batch - number of training examples for one forward/backward pass. So pass in batch data values then update weights. \n",
    "        for batch in train_loader:\n",
    "            # Remember, it's in batches. \n",
    "            x_vals, y_vals = batch\n",
    "            \n",
    "            '''\n",
    "\n",
    "            Reset gradients to 0 so updating of weights can be done correctly.\n",
    "\n",
    "            When we do loss.backward(), gradients are calculated. Then, optimizer.step() does gradient descent.\n",
    "            For the next batch, we don't want these gradients to still be lingering (because a new input will have new gradients).\n",
    "            Thus, we have to reset the gradients to 0. \n",
    "\n",
    "            NOTE: This is not the same as setting the weights to 0! We are just resetting the calculated gradients.\n",
    "            \n",
    "            '''\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calculate model outputs\n",
    "            outputs = model(x_vals)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, y_vals)\n",
    "\n",
    "            # Calculate gradients \n",
    "            loss.backward()\n",
    "\n",
    "            # Do gradient descent to update the weights.\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "\n",
    "        loss = running_loss / len(train_loader)\n",
    "        train_loss_hist.append(loss)\n",
    "\n",
    "\n",
    "        running_val_loss = 0.0\n",
    "        # Calculate val loss\n",
    "        for x, y in val_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Calculate model outputs\n",
    "            val_outputs = model(x)\n",
    "\n",
    "            loss = criterion(val_outputs, y)\n",
    "            running_val_loss += loss\n",
    "\n",
    "        val_loss = running_val_loss / len(val_loader)\n",
    "        val_loss_hist.append(val_loss)\n",
    "\n",
    "\n",
    "        print(f'Epoch {epoch + 1} of {NUM_EPOCHS}, Train Loss: {loss}, Val Loss: {val_loss}')\n",
    "        # print(f'Epoch {epoch + 1} of {NUM_EPOCHS}, Train Loss: {loss}')\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            save_decoded_image(x_vals.cpu().data, name='./Saved_Images/noisy{}.png'.format(epoch))\n",
    "            save_decoded_image(outputs.cpu().data, name='./Saved_Images/denoised{}.png'.format(epoch))\n",
    "        \n",
    "        epoch += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, NUM_EPOCHS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_performance(model, data_loader):\n",
    "    total_loss = 0.0\n",
    "    for x, y in data_loader:\n",
    "        pred = model(x)\n",
    "\n",
    "        total_loss += criterion(pred, y)\n",
    "        \n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "print(eval_performance(model, val_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_sample(model, data_loader):\n",
    "    for x, y in data_loader:\n",
    "        pred = model(x)\n",
    "        \n",
    "        # [0] because 1 channel so need to go inside\n",
    "        hp.mollview(torch.reshape(x[0], (NUMPIX, )))\n",
    "        hp.mollview(torch.reshape(y[0], (NUMPIX, )))\n",
    "        hp.mollview(np.reshape(pred[0].detach().numpy(), (NUMPIX, )))\n",
    "        break\n",
    "\n",
    "display_sample(model, val_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_loss = round(float(train_loss_hist[-1]), 3)\n",
    "final_val_loss = round(float(val_loss_hist[-1]), 3)\n",
    "\n",
    "name = f\"saved_models/model_NSIDE{NSIDE}_trainloss{final_train_loss}_valloss{final_val_loss}_epochs{epoch}.pth\"\n",
    "\n",
    "torch.save(model.state_dict(), name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nn_response')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a63c20d5ea98d5ea615593d44a9fb564882bf3b15df23c63fb54c70ca4209996"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
